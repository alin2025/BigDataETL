{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd9f532-cf2a-4e9a-9ee8-89c9a3844256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.endpoint\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.access.key\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.path.style.access\n",
      "Warning: Ignoring non-Spark config property: fs.s3a.secret.key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/developer/.ivy2/cache\n",
      "The jars for the packages stored in: /home/developer/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-337dd2c8-2d6c-447a-a8c0-ca5974d1699a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.2 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.2 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.6.0 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.8-1 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.2 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      ":: resolution report :: resolve 420ms :: artifacts dl 14ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.4.8-1 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.6.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.1.2 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.2 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-337dd2c8-2d6c-447a-a8c0-ca5974d1699a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 9 already retrieved (0kB/10ms)\n",
      "24/09/19 12:22:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/19 12:22:58 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-684e6161-bfa1-447c-84a4-03295359ef74. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "24/09/19 12:22:58 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "24/09/19 12:22:59 WARN AdminClientConfig: The configuration 'key.deserializer' was supplied but isn't a known config.\n",
      "24/09/19 12:22:59 WARN AdminClientConfig: The configuration 'value.deserializer' was supplied but isn't a known config.\n",
      "24/09/19 12:22:59 WARN AdminClientConfig: The configuration 'enable.auto.commit' was supplied but isn't a known config.\n",
      "24/09/19 12:22:59 WARN AdminClientConfig: The configuration 'max.poll.records' was supplied but isn't a known config.\n",
      "24/09/19 12:22:59 WARN AdminClientConfig: The configuration 'auto.offset.reset' was supplied but isn't a known config.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+---+-----+\n",
      "|key|value|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 6\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"1\",...|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "RuntimeError: reentrant call inside <_io.BufferedReader name=59>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/context.py\", line 377, in signal_handler\n",
      "    self.cancelAllJobs()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/context.py\", line 2255, in cancelAllJobs\n",
      "    self._jsc.sc().cancelAllJobs()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\", line 169, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o31.sc\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 7\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o118.awaitTermination",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 97\u001b[0m\n\u001b[1;32m     81\u001b[0m taxiTripsDF \u001b[38;5;241m=\u001b[39m taxiTripsDF\\\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_and_fwd_flag\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextra\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtolls_amount\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmta_tax\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimprovement_surcharge\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrip_type\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratecodeid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropoff_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPaymentType\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTripStartDT\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTripEndDT\u001b[39m\u001b[38;5;124m'\u001b[39m)\\\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassenger_count > 0 and passenger_count < 8  AND tip_amount >= 0 AND tip_amount < 30 AND fare_amount >= 1 AND fare_amount < 150 AND trip_distance > 0 AND trip_distance < 100 \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# taxiTripsDF.printSchema()\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# taxiTripsDF.show(8,False)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m socketDF \u001b[38;5;241m=\u001b[39m \u001b[43msocketDF\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriteStream\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconsole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputMode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m---> 97\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# s3_query = taxiTripsDF\\\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m#     .writeStream\\\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m#             .format(\"console\")\\\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#             .outputMode(\"append\")\\\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m#             .start()\\\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m#             .awaitTermination()\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/streaming/query.py:201\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o118.awaitTermination"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 8\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 9\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 10\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"1\",...|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 11\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"1\",...|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 12\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 13\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 14\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 15\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 16\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"2\",...|\n",
      "+----+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 17\n",
      "-------------------------------------------\n",
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|null|{\"vendorid\": \"1\",...|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import types as t\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "\n",
    "#================== connection between  spark and kafka=======================================#\n",
    "#==============================================================================================\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName('taxi') \\\n",
    "        .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2') \\\n",
    "        .config(\"fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "        .config(\"fs.s3a.access.key\", \"minioadmin\") \\\n",
    "        .config(\"fs.s3a.secret.key\", \"minioadmin\") \\\n",
    "        .config(\"fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "        .getOrCreate()\n",
    "#==============================================================================================\n",
    "#=========================================== ReadStream from kafka===========================#\n",
    "socketDF = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"course-kafka:9092\") \\\n",
    "    .option(\"Subscribe\", \"my_trip\")\\\n",
    "    .load()\\\n",
    "    .selectExpr(\"CAST(key AS STRING)\",\"CAST(value AS STRING)\")\n",
    "#==============================================================================================\n",
    "#==============================Create schema for create df from json=========================#\n",
    "schema = t.StructType() \\\n",
    "    .add(\"vendorid\", t.StringType())                    .add(\"lpep_pickup_datetime\", t.StringType()) \\\n",
    "    .add(\"lpep_dropoff_datetime\", t.StringType())       .add(\"store_and_fwd_flag\", t.StringType()) \\\n",
    "    .add(\"ratecodeid\", t.StringType())                  .add(\"pickup_longitude\", t.StringType()) \\\n",
    "    .add(\"pickup_latitude\", t.StringType())             .add(\"dropoff_longitude\", t.StringType()) \\\n",
    "    .add(\"dropoff_latitude\", t.StringType())            .add(\"passenger_count\", t.StringType()) \\\n",
    "    .add(\"trip_distance\", t.StringType())               .add(\"fare_amount\", t.StringType()) \\\n",
    "    .add(\"extra\", t.StringType())                       .add(\"mta_tax\", t.StringType()) \\\n",
    "    .add(\"tip_amount\", t.StringType())                  .add(\"tolls_amount\", t.StringType()) \\\n",
    "    .add(\"improvement_surcharge\", t.StringType())       .add(\"total_amount\", t.StringType())\\\n",
    "    .add(\"payment_type\", t.StringType())                .add(\"trip_type\", t.StringType())\n",
    "\n",
    "#==============================================================================================\n",
    "#==========================change json to dataframe with schema==============================#\n",
    "taxiTripsDF = socketDF.select(f.col(\"value\").cast(\"string\")).select(f.from_json(f.col(\"value\"), schema).alias(\"value\")).select(\"value.*\")\n",
    "\n",
    "#====# 1: Remove spaces from column names====================================================#\n",
    "taxiTripsDF = taxiTripsDF \\\n",
    "    .withColumnRenamed(\"vendorid\", \"vendorid\")                          .withColumnRenamed(\"lpep_pickup_datetime\", \"pickup_datetime\") \\\n",
    "    .withColumnRenamed(\"lpep_dropoff_datetime\", \"dropoff_datetime\")     .withColumnRenamed(\"passenger_count\", \"passenger_count\") \\\n",
    "    .withColumnRenamed(\"trip_distance\", \"trip_distance\")                .withColumnRenamed(\"ratecodeid\", \"ratecodeid\") \\\n",
    "    .withColumnRenamed(\"store_and_fwd_flag\", \"store_and_fwd_flag\")      .withColumnRenamed(\"payment_type\", \"PaymentType\")\n",
    "\n",
    "\n",
    "#============================================================================================#\n",
    "#==== 3: Add date columns from timestamp=====================================================#\n",
    "#============================================================================================#\n",
    "taxiTripsDF = taxiTripsDF.withColumn('TripStartDT', taxiTripsDF['pickup_datetime'].cast('date'))\n",
    "taxiTripsDF = taxiTripsDF.withColumn('TripEndDT', taxiTripsDF['dropoff_datetime'].cast('date'))\n",
    "\n",
    "#============================================================================================#\n",
    "#==== 4: Add/convert/casting Additional columns types=========================================#\n",
    "#============================================================================================#\n",
    "taxiTripsDF = taxiTripsDF\\\n",
    "    .withColumn('trip_distance', taxiTripsDF['trip_distance'].cast('double'))\\\n",
    "    .withColumn('pickup_longitude', taxiTripsDF['pickup_longitude'].cast('double')) \\\n",
    "    .withColumn('pickup_latitude', taxiTripsDF['pickup_latitude'].cast('double')) \\\n",
    "    .withColumn('dropoff_longitude', taxiTripsDF['dropoff_longitude'].cast('double')) \\\n",
    "    .withColumn('dropoff_latitude', taxiTripsDF['dropoff_latitude'].cast('double'))\n",
    "\n",
    "taxiTripsDF = taxiTripsDF\\\n",
    "    .withColumn(\"hourd\", hour(taxiTripsDF[\"pickup_datetime\"])) \\\n",
    "    .withColumn(\"minuted\", minute(taxiTripsDF[\"pickup_datetime\"])) \\\n",
    "    .withColumn(\"secondd\", second(taxiTripsDF[\"pickup_datetime\"]))\\\n",
    "    .withColumn(\"dayofweek\", dayofweek(taxiTripsDF[\"TripStartDT\"])) \\\n",
    "    .withColumn(\"week_day_full\", date_format(col(\"TripStartDT\"), \"EEEE\"))\n",
    "\n",
    "## CREATE A CLEANED DATA-FRAME BY DROPPING SOME UN-NECESSARY COLUMNS & FILTERING FOR UNDESIRED VALUES OR OUTLIERS\n",
    "taxiTripsDF = taxiTripsDF\\\n",
    "    .drop('store_and_fwd_flag','fare_amount','extra','tolls_amount','mta_tax','improvement_surcharge','trip_type','ratecodeid','pickup_datetime','dropoff_datetime','PaymentType','TripStartDT','TripEndDT')\\\n",
    "    .filter(\"passenger_count > 0 and passenger_count < 8  AND tip_amount >= 0 AND tip_amount < 30 AND fare_amount >= 1 AND fare_amount < 150 AND trip_distance > 0 AND trip_distance < 100 \")\n",
    "\n",
    "\n",
    "# taxiTripsDF.printSchema()\n",
    "# taxiTripsDF.show(8,False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "socketDF = socketDF\\\n",
    "    .writeStream\\\n",
    "            .format(\"console\")\\\n",
    "            .outputMode(\"append\")\\\n",
    "            .start()\\\n",
    "            .awaitTermination()\n",
    "\n",
    "\n",
    "# s3_query = taxiTripsDF\\\n",
    "#     .writeStream\\\n",
    "#             .format(\"console\")\\\n",
    "#             .outputMode(\"append\")\\\n",
    "#             .start()\\\n",
    "#             .awaitTermination()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bac02b-db25-4524-a58a-2cf8abd26eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
